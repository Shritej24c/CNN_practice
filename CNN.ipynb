{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shritej24c/CNN_practice/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhEl9RWfBXOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H5DghN_BdFr",
        "colab_type": "code",
        "outputId": "71a6fcbf-615a-44a4-a25f-3a78cea25faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99jmcR6GX-U3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "8e27b76f-2d94-43a3-ed43-2220f56d400f"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(y_test.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR5NEyE8I2ED",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-EZHIAw7ASR",
        "colab_type": "code",
        "outputId": "bd281bfc-b89a-4dbb-c51b-3157679a216a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, Flatten, Dense,  MaxPooling2D, Conv2D, Dropout\n",
        "from keras.optimizers import SGD, Adam, rmsprop\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.convolutional import Conv2D\n",
        "\n",
        "\n",
        "#Datasets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "ytrain = to_categorical(y_train,10)\n",
        "ytest = to_categorical(y_test,10)\n",
        "\n",
        "#Initializing the CNN\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Step 1 - Convolutional\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3),input_shape=(32, 32, 3),activation=\"relu\"))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',activation='relu'))\n",
        "\n",
        "#Step 2 - Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Dropout \n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Adding the convolutional layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Step 3 - Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "#Step 4 - Dense\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "# initiate RMSprop optimizer\n",
        "opt = rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# fit model\n",
        "history = model.fit(x_train, ytrain, batch_size=32,validation_data=(x_test, ytest), epochs=100, verbose=0, shuffle=True)\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(x_train, ytrain, verbose=0)\n",
        "_, test_acc = model.evaluate(x_test, ytest, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 0.998, Test: 0.789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-WnajVqDbr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "2653f214-cad9-4501-d24f-3eadefd4fe00"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, Flatten, Dense,  MaxPooling2D, Conv2D, Dropout\n",
        "from keras.optimizers import SGD, Adam, rmsprop, Nadam\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.convolutional import Conv2D\n",
        "\n",
        "\n",
        "#Datasets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "ytrain = to_categorical(y_train,10)\n",
        "ytest = to_categorical(y_test,10)\n",
        "\n",
        "#Initializing the CNN\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Step 1 - Convolutional\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3),input_shape=(32, 32, 3),activation=\"relu\"))\n",
        "#model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',activation='relu'))\n",
        "\n",
        "#Step 2 - Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Dropout \n",
        "\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#Adding the convolutional layer\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#Step 3 - Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "#Step 4 - Dense\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "# initiate RMSprop optimizer\n",
        "opt = rmsprop(lr=0.0001, decay=1e-6)\n",
        "optimizer = Nadam(lr=0.002,\n",
        "                  beta_1=0.9,\n",
        "                  beta_2=0.999,\n",
        "                  epsilon=1e-08,\n",
        "                  schedule_decay=0.004)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# fit model\n",
        "history = model.fit(x_train, ytrain, batch_size=32,validation_data=(x_test, ytest), epochs=100, verbose=0, shuffle=True)\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(x_train, ytrain, verbose=0)\n",
        "_, test_acc = model.evaluate(x_test, ytest, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 20s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train: 0.901, Test: 0.715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jErs75VFCejg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "18c90845-c3f6-4958-d3e4-d684b9372db9"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, Flatten, Dense,  MaxPooling2D, Conv2D, Dropout\n",
        "from keras.optimizers import SGD, Adam, rmsprop, Nadam\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.regularizers import l2\n",
        "\n",
        "#Datasets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "ytrain = to_categorical(y_train,10)\n",
        "ytest = to_categorical(y_test,10)\n",
        "\n",
        "#Initializing the CNN classifier \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Step 1 - Convolutional\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', input_shape=(32, 32, 3),activation=\"relu\"))\n",
        "#model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',activation='relu'))\n",
        "\n",
        "#Step 2 - Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Dropout \n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Adding the convolutional layer\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Step 3 - Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "#Step 4 - Dense\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "# initiate RMSprop optimizer\n",
        "opt = rmsprop(lr=0.0001, decay=1e-6)\n",
        "optimizer = Nadam(lr=0.002,\n",
        "                  beta_1=0.9,\n",
        "                  beta_2=0.999,\n",
        "                  epsilon=1e-08,\n",
        "                  schedule_decay=0.004)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# fit model\n",
        "history = model.fit(x_train, ytrain, batch_size=32, validation_data = (x_test, ytest), epochs=100, verbose=0, shuffle=True)\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(x_train, ytrain, verbose=0)\n",
        "_, test_acc = model.evaluate(x_test, ytest, verbose=0)\n",
        "print('Train: %.3f' % (train_acc))\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 0.988\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waPa5qwKYk58",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "eee7a857-8498-45c2-c381-efdc5f0b269b"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "# predict probabilities for test set\n",
        "yhat_probs = model.predict(x_test, verbose=0)\n",
        "# predict crisp classes for test set\n",
        "yhat_classes = model.predict_classes(x_test, verbose=0)\n",
        "# reduce to 1d array\n",
        "print(yhat_classes)\n",
        "yhat_prob = yhat_probs\n",
        "yhat_class = yhat_classes\n",
        " \n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(y_test, yhat_classes)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "#precision = precision_score(y_test, yhat_classes)\n",
        "#print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "#recall = recall_score(y_test, yhat_classes)\n",
        "#print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(y_test, yhat_classes)\n",
        "report = classification_report(y_test, yhat_classes)\n",
        "print(matrix)\n",
        "print(report)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 1 8 ... 5 1 7]\n",
            "Accuracy: 0.754200\n",
            "[[827  12  31  11  18  10  10  17  46  18]\n",
            " [ 24 856   7   5   5   4   9   7  27  56]\n",
            " [ 65   2 628  50  86  57  63  30  11   8]\n",
            " [ 19   6  56 479  67 220  95  39   6  13]\n",
            " [ 17   4  55  32 733  48  42  61   5   3]\n",
            " [  9   4  24  91  57 707  47  50   6   5]\n",
            " [  6   4  32  28  33  20 869   3   2   3]\n",
            " [ 13   0  15  22  43  54  10 836   1   6]\n",
            " [ 70  34  16   6  10   6   7   9 825  17]\n",
            " [ 49  75  12  14   4   9  10  20  25 782]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.83      0.79      1000\n",
            "           1       0.86      0.86      0.86      1000\n",
            "           2       0.72      0.63      0.67      1000\n",
            "           3       0.65      0.48      0.55      1000\n",
            "           4       0.69      0.73      0.71      1000\n",
            "           5       0.62      0.71      0.66      1000\n",
            "           6       0.75      0.87      0.80      1000\n",
            "           7       0.78      0.84      0.81      1000\n",
            "           8       0.86      0.82      0.84      1000\n",
            "           9       0.86      0.78      0.82      1000\n",
            "\n",
            "   micro avg       0.75      0.75      0.75     10000\n",
            "   macro avg       0.75      0.75      0.75     10000\n",
            "weighted avg       0.75      0.75      0.75     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkFNfheQOaCz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bde7657c-92e9-4db6-8e3e-a65ec2ab2811"
      },
      "source": [
        "print(test_acc)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GGOyvSzPzqj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5d73ff13-6f83-4893-ad1e-b98a13084f44"
      },
      "source": [
        "import numpy as np\n",
        "recall = np.diag(matrix) / np.sum(matrix, axis = 1)\n",
        "precision = np.diag(matrix) / np.sum(matrix, axis = 0)\n",
        "print(recall)\n",
        "print(precision)\n",
        "print(np.mean(recall))\n",
        "print(np.mean(precision))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.827 0.856 0.628 0.479 0.733 0.707 0.869 0.836 0.825 0.782]\n",
            "[0.75250227 0.85857573 0.71689498 0.64905149 0.69412879 0.62290749\n",
            " 0.74784854 0.77985075 0.86477987 0.85839737]\n",
            "0.7542000000000001\n",
            "0.7544937269546279\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}