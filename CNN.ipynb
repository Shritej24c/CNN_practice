{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shritej24c/CNN_practice/blob/master/CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhEl9RWfBXOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7H5DghN_BdFr",
        "colab_type": "code",
        "outputId": "71a6fcbf-615a-44a4-a25f-3a78cea25faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99jmcR6GX-U3",
        "colab_type": "code",
        "outputId": "8e27b76f-2d94-43a3-ed43-2220f56d400f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (50000, 32, 32, 3)\n",
            "50000 train samples\n",
            "(10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qR5NEyE8I2ED",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-EZHIAw7ASR",
        "colab_type": "code",
        "outputId": "bd281bfc-b89a-4dbb-c51b-3157679a216a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, Flatten, Dense,  MaxPooling2D, Conv2D, Dropout\n",
        "from keras.optimizers import SGD, Adam, rmsprop\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.convolutional import Conv2D\n",
        "\n",
        "\n",
        "#Datasets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "ytrain = to_categorical(y_train,10)\n",
        "ytest = to_categorical(y_test,10)\n",
        "\n",
        "#Initializing the CNN\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Step 1 - Convolutional\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3),input_shape=(32, 32, 3),activation=\"relu\"))\n",
        "model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',activation='relu'))\n",
        "\n",
        "#Step 2 - Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Dropout \n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Adding the convolutional layer\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Step 3 - Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "#Step 4 - Dense\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "# initiate RMSprop optimizer\n",
        "opt = rmsprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# fit model\n",
        "history = model.fit(x_train, ytrain, batch_size=32,validation_data=(x_test, ytest), epochs=100, verbose=0, shuffle=True)\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(x_train, ytrain, verbose=0)\n",
        "_, test_acc = model.evaluate(x_test, ytest, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train: 0.998, Test: 0.789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nd-WnajVqDbr",
        "colab_type": "code",
        "outputId": "2653f214-cad9-4501-d24f-3eadefd4fe00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D, Flatten, Dense,  MaxPooling2D, Conv2D, Dropout\n",
        "from keras.optimizers import SGD, Adam, rmsprop, Nadam\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.convolutional import Conv2D\n",
        "\n",
        "\n",
        "#Datasets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "ytrain = to_categorical(y_train,10)\n",
        "ytest = to_categorical(y_test,10)\n",
        "\n",
        "#Initializing the CNN\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Step 1 - Convolutional\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3),input_shape=(32, 32, 3),activation=\"relu\"))\n",
        "#model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',activation='relu'))\n",
        "\n",
        "#Step 2 - Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Dropout \n",
        "\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#Adding the convolutional layer\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "#Step 3 - Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "#Step 4 - Dense\n",
        "model.add(Dense(units=128, activation='relu'))\n",
        "model.add(Dense(units=10, activation='softmax'))\n",
        "\n",
        "# compile model\n",
        "# initiate RMSprop optimizer\n",
        "opt = rmsprop(lr=0.0001, decay=1e-6)\n",
        "optimizer = Nadam(lr=0.002,\n",
        "                  beta_1=0.9,\n",
        "                  beta_2=0.999,\n",
        "                  epsilon=1e-08,\n",
        "                  schedule_decay=0.004)\n",
        "\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# fit model\n",
        "history = model.fit(x_train, ytrain, batch_size=32,validation_data=(x_test, ytest), epochs=100, verbose=0, shuffle=True)\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(x_train, ytrain, verbose=0)\n",
        "_, test_acc = model.evaluate(x_test, ytest, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 20s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train: 0.901, Test: 0.715\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jErs75VFCejg",
        "colab_type": "code",
        "outputId": "1fe88771-aa8e-4e2a-83b1-15b484a7f807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, MaxPooling2D, Dropout\n",
        "from keras.optimizers import SGD, Adam, rmsprop, Nadam\n",
        "from keras.datasets import cifar10\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.regularizers import l2\n",
        "\n",
        "#Datasets\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "\n",
        "input_shape = x_train.shape[1:]\n",
        "num_classes = 10\n",
        "\n",
        "ytrain = to_categorical(y_train, num_classes)\n",
        "ytest = to_categorical(y_test, num_classes)\n",
        "\n",
        "#Initializing the CNN classifier \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Step 1 - Convolutional\n",
        "model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', input_shape=input_shape, activation=\"relu\"))\n",
        "#model.add(Conv2D(filters=32, kernel_size=(3,3), padding='same',activation='relu'))\n",
        "\n",
        "#Step 2 - Pooling\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "#Dropout \n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Adding the convolutional layer\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
        "#model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Step 3 - Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "#Step 4 - Dense\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = rmsprop(lr=0.0001, decay=1e-6)\n",
        "optimizer = Nadam(lr=0.002,\n",
        "                  beta_1=0.9,\n",
        "                  beta_2=0.999,\n",
        "                  epsilon=1e-08,\n",
        "                  schedule_decay=0.004)\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# fit model\n",
        "history = model.fit(x_train, ytrain, batch_size=32, validation_data = (x_test, ytest), epochs=100, verbose=0, shuffle=True)\n",
        "\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(x_train, ytrain, verbose=0)\n",
        "_, test_acc = model.evaluate(x_test, ytest, verbose=0)\n",
        "print('Train Accuracy : %.3f' % (train_acc))\n",
        "print('Test Accuracy : %.3f' %(test_acc))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# predict probabilities for test set\n",
        "yhat_probs = model.predict(x_test, verbose=0)\n",
        "# predict crisp classes for test set\n",
        "yhat_classes = model.predict_classes(x_test, verbose=0)\n",
        "\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(y_test, yhat_classes)\n",
        "report = classification_report(y_test, yhat_classes)\n",
        "print('Confusion matrix : \\n', matrix)\n",
        "print(report)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 13s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train Accuracy : 0.992\n",
            "Test Accuracy : 0.748\n",
            "Confusion matrix : \n",
            " [[812  17  55   9   7   8  15  12  39  26]\n",
            " [ 16 838   4   7   6   6  11   4  27  81]\n",
            " [ 59   4 686  39  65  56  57  21   7   6]\n",
            " [ 20   9  91 501  49 200  60  40   9  21]\n",
            " [ 13   5  95  38 671  48  51  66   8   5]\n",
            " [ 12   3  63 125  40 685  26  37   2   7]\n",
            " [ 10   4  49  27  27  28 840   6   5   4]\n",
            " [ 20   3  35  29  38  52   7 801   2  13]\n",
            " [ 57  36  24  10   5  10   8   2 827  21]\n",
            " [ 39  63   7  11   3  12   4  18  26 817]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.81      0.79      1000\n",
            "           1       0.85      0.84      0.85      1000\n",
            "           2       0.62      0.69      0.65      1000\n",
            "           3       0.63      0.50      0.56      1000\n",
            "           4       0.74      0.67      0.70      1000\n",
            "           5       0.62      0.69      0.65      1000\n",
            "           6       0.78      0.84      0.81      1000\n",
            "           7       0.80      0.80      0.80      1000\n",
            "           8       0.87      0.83      0.85      1000\n",
            "           9       0.82      0.82      0.82      1000\n",
            "\n",
            "   micro avg       0.75      0.75      0.75     10000\n",
            "   macro avg       0.75      0.75      0.75     10000\n",
            "weighted avg       0.75      0.75      0.75     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "waPa5qwKYk58",
        "colab_type": "code",
        "outputId": "eee7a857-8498-45c2-c381-efdc5f0b269b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "# predict probabilities for test set\n",
        "yhat_probs = model.predict(x_test, verbose=0)\n",
        "# predict crisp classes for test set\n",
        "yhat_classes = model.predict_classes(x_test, verbose=0)\n",
        "# reduce to 1d array\n",
        "print(yhat_classes)\n",
        "yhat_prob = yhat_probs\n",
        "yhat_class = yhat_classes\n",
        " \n",
        "# accuracy: (tp + tn) / (p + n)\n",
        "accuracy = accuracy_score(y_test, yhat_classes)\n",
        "print('Accuracy: %f' % accuracy)\n",
        "# precision tp / (tp + fp)\n",
        "#precision = precision_score(y_test, yhat_classes)\n",
        "#print('Precision: %f' % precision)\n",
        "# recall: tp / (tp + fn)\n",
        "#recall = recall_score(y_test, yhat_classes)\n",
        "#print('Recall: %f' % recall)\n",
        "# f1: 2 tp / (2 tp + fp + fn)\n",
        "\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(y_test, yhat_classes)\n",
        "report = classification_report(y_test, yhat_classes)\n",
        "print('Confusion matrix : \\n', matrix)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[3 1 8 ... 5 1 7]\n",
            "Accuracy: 0.754200\n",
            "[[827  12  31  11  18  10  10  17  46  18]\n",
            " [ 24 856   7   5   5   4   9   7  27  56]\n",
            " [ 65   2 628  50  86  57  63  30  11   8]\n",
            " [ 19   6  56 479  67 220  95  39   6  13]\n",
            " [ 17   4  55  32 733  48  42  61   5   3]\n",
            " [  9   4  24  91  57 707  47  50   6   5]\n",
            " [  6   4  32  28  33  20 869   3   2   3]\n",
            " [ 13   0  15  22  43  54  10 836   1   6]\n",
            " [ 70  34  16   6  10   6   7   9 825  17]\n",
            " [ 49  75  12  14   4   9  10  20  25 782]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.75      0.83      0.79      1000\n",
            "           1       0.86      0.86      0.86      1000\n",
            "           2       0.72      0.63      0.67      1000\n",
            "           3       0.65      0.48      0.55      1000\n",
            "           4       0.69      0.73      0.71      1000\n",
            "           5       0.62      0.71      0.66      1000\n",
            "           6       0.75      0.87      0.80      1000\n",
            "           7       0.78      0.84      0.81      1000\n",
            "           8       0.86      0.82      0.84      1000\n",
            "           9       0.86      0.78      0.82      1000\n",
            "\n",
            "   micro avg       0.75      0.75      0.75     10000\n",
            "   macro avg       0.75      0.75      0.75     10000\n",
            "weighted avg       0.75      0.75      0.75     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08DETQJg1Y4T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model, model_from_json\n",
        "import h5py\n",
        "\n",
        "model.save(\"digit-recognizer\\classifier.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CaJHDXQ7OsV",
        "colab_type": "code",
        "outputId": "a3060b37-60cb-4c03-ded6-c1b2e6993a47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "print(x_test.shape)\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10000, 32, 32, 3)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,064,362\n",
            "Trainable params: 1,064,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI_hnz1d7huQ",
        "colab_type": "code",
        "outputId": "c0e84097-97fa-4cd6-a36c-9bf712ffd4eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "loaded_model = load_model('digit-recognizer\\classifier.h5')\n",
        "\n",
        "loaded_model.summary()\n",
        "\n",
        "import random\n",
        "\n",
        "y_prob = loaded_model.predict(x_test[0:2,:,:,:], verbose=0)\n",
        "\n",
        "y_class = loaded_model.predict_classes(x_test[0:2,:,:,:], verbose=0)\n",
        "\n",
        "print(y_prob)\n",
        "print(y_class)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 16, 16, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1049088   \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,064,362\n",
            "Trainable params: 1,064,362\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "[[2.6690651e-04 2.9190599e-07 8.4843428e-04 8.4988356e-01 2.8332823e-04\n",
            "  1.4402229e-01 3.8431038e-03 8.0021081e-04 5.1477982e-05 4.8600191e-07]\n",
            " [9.9406030e-08 1.6674289e-04 6.6819662e-13 1.2343296e-12 1.4182124e-14\n",
            "  6.0036950e-14 4.6423054e-14 3.8697722e-16 9.9983311e-01 5.5744237e-10]]\n",
            "[3 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2axhA-Rng5eF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "import io\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkFNfheQOaCz",
        "colab_type": "code",
        "outputId": "bde7657c-92e9-4db6-8e3e-a65ec2ab2811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(test_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GGOyvSzPzqj",
        "colab_type": "code",
        "outputId": "5d73ff13-6f83-4893-ad1e-b98a13084f44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import numpy as np\n",
        "recall = np.diag(matrix) / np.sum(matrix, axis = 1)\n",
        "precision = np.diag(matrix) / np.sum(matrix, axis = 0)\n",
        "print(recall)\n",
        "print(precision)\n",
        "print(np.mean(recall))\n",
        "print(np.mean(precision))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.827 0.856 0.628 0.479 0.733 0.707 0.869 0.836 0.825 0.782]\n",
            "[0.75250227 0.85857573 0.71689498 0.64905149 0.69412879 0.62290749\n",
            " 0.74784854 0.77985075 0.86477987 0.85839737]\n",
            "0.7542000000000001\n",
            "0.7544937269546279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDYVIP18dj38",
        "colab_type": "code",
        "outputId": "360a72ca-5c73-4526-d961-3e7df9c0f7df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-3caefa261807>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMRYnCnpWerW",
        "colab_type": "code",
        "outputId": "7e7c0ec0-bc0a-4a6f-e6a6-caead8460441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "4+4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d52c8pFXWj_7",
        "colab_type": "code",
        "outputId": "a64c1b14-f676-418b-c9ba-d2dde36df919",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "train_data = pd.read_csv(\"digit-recognizer\\train.csv\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e4cdd0d99056>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"digit-recognizer\\train.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'digit-recognizer\\train.csv' does not exist: b'digit-recognizer\\train.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0iAQpkBXWfz",
        "colab_type": "code",
        "outputId": "5bf5a9b8-ff80-441e-fad5-aebab9cab2e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "import os\n",
        "print(os.path())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-0f5c205c2dab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbzuiH9hbmLw",
        "colab_type": "code",
        "outputId": "ad4d1788-4b83-4a73-f701-591905765a2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical \n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers import Dense, MaxPooling1D, Dropout, Flatten\n",
        "from keras.models import Sequential \n",
        "from keras.optimizers import SGD, Adam, rmsprop, Nadam, Adadelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "num_classes = 10\n",
        "\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/Shritej24c/CNN_practice/master/digit-recognizer/train.csv')\n",
        "\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/Shritej24c/CNN_practice/master/digit-recognizer/test.csv')\n",
        "\n",
        "\n",
        "train = np.array(train_data)\n",
        "test = np.array(test_data)\n",
        "\n",
        "ytrain = train[:,0]\n",
        "xtrain = np.reshape(train[:,1:],(42000,28,28))\n",
        "\n",
        "xtrain, xtest, ytrain, y_test = train_test_split(xtrain, ytrain, test_size = 0.25, random_state = 23)\n",
        "\n",
        "ytrain = to_categorical(ytrain)\n",
        "ytest =  to_categorical(y_test)\n",
        "\n",
        "input_shape = (28,28)\n",
        "\n",
        "\n",
        "#Initializing the CNN classifier \n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#Step 1 - Convolutional\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same', input_shape=input_shape, activation=\"relu\"))\n",
        "model.add(Conv1D(filters=32, kernel_size=3, padding='same',activation='relu'))\n",
        "\n",
        "#Step 2 - Pooling\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "#Dropout \n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Adding the convolutional layer\n",
        "model.add(Conv1D(32, 3, activation='relu', padding='same'))\n",
        "model.add(Conv1D(64, 3, activation='relu', padding='same'))\n",
        "\n",
        "model.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#Step 3 - Flatten\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "#Step 4 - Dense\n",
        "model.add(Dense(units=512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = rmsprop(lr=0.0001, decay=1e-6)\n",
        "optimizer = Nadam(lr=0.002,\n",
        "                  beta_1=0.9,\n",
        "                  beta_2=0.999,\n",
        "                  epsilon=1e-08,\n",
        "                  schedule_decay=0.004)\n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['accuracy'])\n",
        "\n",
        "xtrain = xtrain.astype('float32')\n",
        "xtest = xtest.astype('float32')\n",
        "xtrain /= 255\n",
        "xtest /= 255\n",
        "\n",
        "# fit model\n",
        "history = model.fit(xtrain, ytrain, batch_size=32, validation_data = (xtest, ytest), epochs=100, verbose=0, shuffle=True)\n",
        "\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(xtrain, ytrain, verbose=0)\n",
        "_, test_acc = model.evaluate(xtest, ytest, verbose=0)\n",
        "print('Train Accuracy : %.3f' % (train_acc))\n",
        "print('Test Accuracy : %.3f' %(test_acc))\n",
        "\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# predict probabilities for test set\n",
        "yhat_probs = model.predict(xtest, verbose=0)\n",
        "# predict crisp classes for test set\n",
        "yhat_classes = model.predict_classes(xtest, verbose=0)\n",
        "\n",
        "# confusion matrix\n",
        "matrix = confusion_matrix(y_test, yhat_classes)\n",
        "report = classification_report(y_test, yhat_classes)\n",
        "print('Confusion matrix : \\n', matrix)\n",
        "print(report)\n"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy : 1.000\n",
            "Test Accuracy : 0.990\n",
            "Confusion matrix : \n",
            " [[1049    0    0    0    0    0    0    0    0    1]\n",
            " [   0 1155    0    1    0    0    2    1    2    0]\n",
            " [   1    1 1047    4    0    0    0    2    3    0]\n",
            " [   0    0    1 1076    0    1    0    1    1    4]\n",
            " [   0    1    0    0 1020    0    1    2    3   12]\n",
            " [   0    0    0   10    0  940    0    1    0    1]\n",
            " [   0    0    1    0    2    1 1037    0    0    0]\n",
            " [   0    3    2    0    0    0    0 1066    0    2]\n",
            " [   1    2    3    5    2    1    3    1  980    5]\n",
            " [   0    0    0    1    3    3    0    3    0 1029]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      1050\n",
            "           1       0.99      0.99      0.99      1161\n",
            "           2       0.99      0.99      0.99      1058\n",
            "           3       0.98      0.99      0.99      1084\n",
            "           4       0.99      0.98      0.99      1039\n",
            "           5       0.99      0.99      0.99       952\n",
            "           6       0.99      1.00      1.00      1041\n",
            "           7       0.99      0.99      0.99      1073\n",
            "           8       0.99      0.98      0.98      1003\n",
            "           9       0.98      0.99      0.98      1039\n",
            "\n",
            "   micro avg       0.99      0.99      0.99     10500\n",
            "   macro avg       0.99      0.99      0.99     10500\n",
            "weighted avg       0.99      0.99      0.99     10500\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwrL__KSKYRi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = test.reshape(28000,28,28)\n",
        "\n",
        "pred = model.predict_classes(test,verbose=0)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "df = np.zeros((len(pred),2))\n",
        "\n",
        "for i in range(len(pred)):\n",
        "  df[i] = np.array([i+1, pred[i]])\n",
        "  \n",
        "import csv\n",
        "\n",
        "with open('sample_submission_1.csv', 'w') as csvFile:\n",
        "    writer = csv.writer(csvFile)\n",
        "    writer.writerows(df)\n",
        "\n",
        "csvFile.close()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_PR7LOo2065",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('sample_submission_1.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "446HiFL27yEv",
        "colab_type": "code",
        "outputId": "d6be5c6f-6884-410f-a39d-5532ec073440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(ytest.shape)\n",
        "print(yhat_classes.shape)\n",
        "print(yhat_probs.shape)\n",
        "test = np.reshape(test, (28000,28,28))\n",
        "# predict probabilities for test set\n",
        "pred_probs = model.predict(xtest, verbose=0)\n",
        "# predict crisp classes for test set\n",
        "pred_classes = model.predict_classes(xtest, verbose=0)\n",
        "print(pred_classes.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10500, 10)\n",
            "(10500,)\n",
            "(10500, 10)\n",
            "(10500,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnezdN4OjqJ7",
        "colab_type": "code",
        "outputId": "47c0d291-7439-4e5c-8ebc-2eb4ece25bbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(ytrain[11])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qM5P0dnzoMD",
        "colab_type": "code",
        "outputId": "a49aea36-63f1-4c3a-806f-d540b0eac376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "train_data = pd.read_csv('https://raw.githubusercontent.com/Shritej24c/CNN_practice/master/digit-recognizer/train.csv')\n",
        "\n",
        "test_data = pd.read_csv('https://raw.githubusercontent.com/Shritej24c/CNN_practice/master/digit-recognizer/test.csv')\n",
        "\n",
        "\n",
        "train = np.array(train_data)\n",
        "test = np.array(test_data)\n",
        "\n",
        "ytrain = train[:,0]\n",
        "xtrain = np.reshape(train[:,1:],(42000,28,28))\n",
        "\n",
        "xtrain, xtest, ytrain, ytest = train_test_split(xtrain, ytrain, test_size = 0.25, random_state = 23)\n",
        "\n",
        "print(ytrain.shape)\n",
        "ytrain = to_categorical(ytrain)\n",
        "\n",
        "\n",
        "print(ytrain.shape)\n",
        "print(xtrain.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(31500,)\n",
            "(31500, 10)\n",
            "(31500, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap4LW3qzqnE9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9f078a3f-ab83-430d-fbd3-8010128c0da3"
      },
      "source": [
        "import numpy as np\n",
        "re = np.zeros((3,3))\n",
        "r = np.array([2,33])\n",
        "\n",
        "print(r)\n",
        "\n",
        "re[0] = r\n",
        "print(re)\n",
        "\n",
        "df = pd.DataFrame(re)\n",
        "\n",
        "df.to_csv(\"lame.csv\", sep=\"\\t\",index=False)\n",
        "re"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 2 33]\n",
            "[[ 2. 33.]\n",
            " [ 0.  0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1dCEexSuHWO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('lame.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMBsWY9Ux48e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "\n",
        "with open('person.csv', 'w') as csvFile:\n",
        "    writer = csv.writer(csvFile)\n",
        "    writer.writerows(re)\n",
        "\n",
        "csvFile.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "128uvEwByRsD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('person.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq_hoxKj0CEN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "0cccfee0-67f6-4178-a21e-b81a13ea339b"
      },
      "source": [
        "head = [\"data\", 'label']\n",
        "\n",
        "re[0] = head\n",
        "re[1] = r\n",
        "\n",
        "print(re)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-cdc7a2683ada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhead\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhead\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'data'"
          ]
        }
      ]
    }
  ]
}